"""
Reddit Intelligence Service
Real Reddit data via Apify scraper, with GPT sentiment analysis.
Falls back to brand-aware rich mock data when Apify is unavailable.
"""
import os
import json
import time
import asyncio
import urllib.request
import urllib.error
from typing import Dict, List, Optional
from datetime import datetime


# Apify actor for Reddit
_REDDIT_ACTOR = "trudax~reddit-scraper-lite"


class RedditIntelligenceService:
    """
    Reddit Intelligence with real Apify data + OpenAI KB-aware sentiment.
    Falls back to brand-specific rich mock data when API is unavailable.
    """

    def __init__(self):
        # Lazy loaded ‚Äî picked up fresh on every call
        pass

    def _apify_key(self) -> Optional[str]:
        return os.getenv("APIFY_API_KEY")

    def _openai_key(self) -> Optional[str]:
        return os.getenv("OPENAI_API_KEY")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Public API
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def get_reddit_metrics(self, brand_name: str = "default") -> Dict:
        threads = await self.get_reddit_threads(brand_name)
        if not threads:
            return {
                "positive_sentiment_pct": 0.0,
                "total_mention_rate": 0.0,
                "positive_mentions": 0,
                "total_mentions": 0,
                "change_vs_previous": 0.0,
                "reddit_share_of_citations": 0.0,
            }
        total_mentions = sum(1 for t in threads if t.get("brand_mentioned", 0) > 0)
        positive_mentions = sum(
            1 for t in threads
            if t.get("sentiment") == "positive" and t.get("brand_mentioned", 0) > 0
        )
        return {
            "positive_sentiment_pct": (positive_mentions / total_mentions * 100) if total_mentions > 0 else 0.0,
            "total_mention_rate": (total_mentions / len(threads) * 100) if threads else 0.0,
            "positive_mentions": positive_mentions,
            "total_mentions": total_mentions,
            "change_vs_previous": 2.4,
            "reddit_share_of_citations": 3.5,
        }

    async def get_reddit_threads(
        self,
        brand_name: str = "default",
        search_query: Optional[str] = None,
        filter_type: Optional[str] = None,
        sentiment_filter: Optional[str] = None,
    ) -> List[Dict]:
        """
        Fetch real Reddit threads from Apify if key is present.
        Falls back to brand-aware rich mock data.
        """
        threads = await self._fetch_from_apify(brand_name)
        if not threads:
            threads = self._rich_mock_data(brand_name)

        # Apply filters
        if search_query:
            threads = [t for t in threads if search_query.lower() in t["title"].lower()]
        if filter_type == "brand":
            threads = [t for t in threads if t.get("brand_mentioned", 0) > 0]
        elif filter_type == "competitor":
            threads = [t for t in threads if any(count > 0 for count in t.get("competitors_mentioned", {}).values())]
        if sentiment_filter and sentiment_filter != "all":
            threads = [t for t in threads if t.get("sentiment") == sentiment_filter]

        return threads

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Apify Integration
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def _fetch_from_apify(self, brand_name: str) -> List[Dict]:
        """Start an Apify run and poll for results. Returns [] on any failure."""
        key = self._apify_key()
        if not key:
            print("‚ö†Ô∏è APIFY_API_KEY not set ‚Äî using mock Reddit data")
            return []

        try:
            loop = asyncio.get_event_loop()
            items = await asyncio.wait_for(
                loop.run_in_executor(None, self._run_apify_sync, key, brand_name),
                timeout=30.0
            )
            if items:
                print(f"‚úÖ Apify returned {len(items)} real Reddit items for '{brand_name}'")
                return self._transform_apify_items(items, brand_name)
            return []
        except asyncio.TimeoutError:
            print("‚ö†Ô∏è Apify timed out ‚Äî using mock Reddit data")
            return []
        except Exception as e:
            print(f"‚ö†Ô∏è Apify error: {e} ‚Äî using mock Reddit data")
            return []

    def _run_apify_sync(self, api_key: str, brand_name: str) -> List[Dict]:
        """Synchronous Apify run+poll (called in executor thread)."""
        # 1. Start the run
        run_input = json.dumps({
            "searches": [f"{brand_name} review site:reddit.com"],
            "maxItems": 8,
            "sort": "relevance",
            "type": "posts",
        }).encode()
        req = urllib.request.Request(
            f"https://api.apify.com/v2/acts/{_REDDIT_ACTOR}/runs",
            data=run_input,
            headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
            method="POST",
        )
        with urllib.request.urlopen(req, timeout=10) as r:
            run_data = json.loads(r.read())
        run_id = run_data["data"]["id"]
        print(f"üîç Apify Reddit run started: {run_id}")

        # 2. Poll for completion (max 20s)
        for _ in range(8):
            time.sleep(3)
            status_req = urllib.request.Request(
                f"https://api.apify.com/v2/actor-runs/{run_id}",
                headers={"Authorization": f"Bearer {api_key}"},
            )
            with urllib.request.urlopen(status_req, timeout=8) as r:
                status_data = json.loads(r.read())
            status = status_data["data"]["status"]
            if status == "SUCCEEDED":
                break
            if status in ("FAILED", "TIMED-OUT", "ABORTED"):
                print(f"‚ö†Ô∏è Apify run {run_id} ended with status: {status}")
                return []

        if status != "SUCCEEDED":
            return []

        # 3. Fetch dataset items
        items_req = urllib.request.Request(
            f"https://api.apify.com/v2/actor-runs/{run_id}/dataset/items?limit=8",
            headers={"Authorization": f"Bearer {api_key}"},
        )
        with urllib.request.urlopen(items_req, timeout=10) as r:
            return json.loads(r.read())

    def _transform_apify_items(self, items: List[Dict], brand_name: str) -> List[Dict]:
        """Convert raw Apify Reddit items into the service's thread format."""
        threads = []
        for idx, item in enumerate(items):
            title = item.get("title", "").strip()
            if not title:
                # It's a comment, not a post ‚Äî skip or use body as title
                title = (item.get("body") or "")[:80].strip() + "..."

            body = item.get("body") or item.get("html") or ""
            subreddit = (
                item.get("communityName")
                or item.get("parsedCommunityName")
                or item.get("subreddit")
                or "reddit"
            )
            # Strip /r/ prefix if present
            if subreddit.startswith("r/"):
                subreddit = subreddit[2:]

            combined_text = f"{title} {body}".lower()
            brand_mentioned = combined_text.count(brand_name.lower())
            # Quick rule-based sentiment
            positive_words = ["love", "great", "amazing", "best", "good", "recommend", "excellent", "happy"]
            negative_words = ["bad", "worst", "hate", "avoid", "poor", "scam", "fraud", "fake", "overpriced"]
            pos_count = sum(combined_text.count(w) for w in positive_words)
            neg_count = sum(combined_text.count(w) for w in negative_words)
            if pos_count > neg_count:
                sentiment, score = "positive", min(0.6 + pos_count * 0.05, 0.95)
            elif neg_count > pos_count:
                sentiment, score = "negative", max(0.45 - neg_count * 0.05, 0.1)
            else:
                sentiment, score = "neutral", 0.55

            threads.append({
                "id": item.get("id", f"apify_{idx}"),
                "rank": idx + 1,
                "title": title or f"Reddit discussion about {brand_name}",
                "url": item.get("url", f"https://reddit.com/r/{subreddit}"),
                "subreddit": subreddit,
                "citations": item.get("score", item.get("upvotes", 0)) or 0,
                "percentage": round(100 / max(len(items), 1), 1),
                "brand_mentioned": brand_mentioned,
                "competitors_mentioned": {},
                "sentiment": sentiment,
                "sentiment_score": round(score, 2),
                "summary": (body or title)[:200].strip() or f"Reddit thread discussing {brand_name}",
                "created_at": item.get("createdAt", datetime.utcnow().isoformat()),
                "is_real": True,
            })
        return threads

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Brand-aware Rich Mock Data (fallback)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def _rich_mock_data(self, brand_name: str) -> List[Dict]:
        """
        Brand-aware mock Reddit threads. Uses the brand_name so it looks
        specific rather than generic payment-processor data.
        """
        b = brand_name
        return [
            {
                "id": "mock_1", "rank": 1,
                "title": f"Honest review of {b} ‚Äî worth the hype?",
                "url": f"https://reddit.com/r/IndianSkincareAddicts/comments/honest_{b.lower()}_review",
                "subreddit": "IndianSkincareAddicts",
                "citations": 847, "percentage": 24.5,
                "brand_mentioned": 18,
                "competitors_mentioned": {"Minimalist": 8, "mCaffeine": 5, "The Derma Co": 4},
                "sentiment": "positive", "sentiment_score": 0.82,
                "summary": f"Community discussion on {b} products. Users praise the natural ingredients and efficacy but note pricing concerns.",
                "created_at": "2024-01-15T10:30:00Z", "is_real": False,
            },
            {
                "id": "mock_2", "rank": 2,
                "title": f"Is {b} genuinely toxin-free or just marketing?",
                "url": f"https://reddit.com/r/IndianSkincareAddicts/comments/{b.lower()}_toxin_free",
                "subreddit": "IndianSkincareAddicts",
                "citations": 623, "percentage": 18.2,
                "brand_mentioned": 22,
                "competitors_mentioned": {"Minimalist": 12, "The Derma Co": 6},
                "sentiment": "neutral", "sentiment_score": 0.55,
                "summary": f"Skeptical discussion about {b}'s toxin-free claims. Some users defend the brand citing MADE SAFE certifications, others question marketing.",
                "created_at": "2024-01-14T15:20:00Z", "is_real": False,
            },
            {
                "id": "mock_3", "rank": 3,
                "title": f"D2C skincare India 2024 ‚Äî {b} vs Minimalist vs The Derma Co",
                "url": "https://reddit.com/r/IndianSkincareAddicts/comments/d2c_skincare_comparison",
                "subreddit": "IndianSkincareAddicts",
                "citations": 534, "percentage": 15.8,
                "brand_mentioned": 15,
                "competitors_mentioned": {"Minimalist": 20, "The Derma Co": 14, "mCaffeine": 9},
                "sentiment": "positive", "sentiment_score": 0.72,
                "summary": f"Comparison thread where {b} wins on brand trust and certifications, Minimalist wins on ingredient concentration value.",
                "created_at": "2024-01-12T09:45:00Z", "is_real": False,
            },
            {
                "id": "mock_4", "rank": 4,
                "title": f"{b} customer service experience ‚Äî sharing my nightmare",
                "url": f"https://reddit.com/r/india/comments/{b.lower()}_customer_service",
                "subreddit": "india",
                "citations": 412, "percentage": 12.1,
                "brand_mentioned": 28,
                "competitors_mentioned": {},
                "sentiment": "negative", "sentiment_score": 0.28,
                "summary": f"User shares bad experience with {b} returns and customer support. Comments thread shows mixed experiences ‚Äî some validate, others say their experience was fine.",
                "created_at": "2024-01-10T14:30:00Z", "is_real": False,
            },
            {
                "id": "mock_5", "rank": 5,
                "title": f"Affordable skincare routine for Indian skin ‚Äî starting with {b}?",
                "url": "https://reddit.com/r/IndianSkincareAddicts/comments/affordable_routine_india",
                "subreddit": "IndianSkincareAddicts",
                "citations": 289, "percentage": 8.5,
                "brand_mentioned": 11,
                "competitors_mentioned": {"Minimalist": 16, "Plum": 7},
                "sentiment": "positive", "sentiment_score": 0.78,
                "summary": f"{b} frequently recommended as an entry-level D2C skincare brand for Indian skin types. High mentions in beginner routine recommendations.",
                "created_at": "2024-01-08T11:15:00Z", "is_real": False,
            },
            {
                "id": "mock_6", "rank": 6,
                "title": f"What are your favourite {b} products? My top 3",
                "url": f"https://reddit.com/r/IndianSkincareAddicts/comments/fav_{b.lower()}_products",
                "subreddit": "IndianSkincareAddicts",
                "citations": 218, "percentage": 6.4,
                "brand_mentioned": 19,
                "competitors_mentioned": {},
                "sentiment": "positive", "sentiment_score": 0.91,
                "summary": f"Enthusiastic thread with users sharing their favourite {b} products. Vitamin C serum, onion hair oil and face wash get top mentions.",
                "created_at": "2024-01-05T16:20:00Z", "is_real": False,
            },
        ]

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Thread analysis (GPT, KB-aware)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def analyze_thread_with_kb(
        self,
        thread_title: str,
        thread_content: str,
        knowledge_base: Dict
    ) -> Dict:
        """GPT-powered KB-aware sentiment analysis of a Reddit thread."""
        api_key = self._openai_key()
        if not api_key:
            return {"sentiment": "neutral", "sentiment_score": 0.5, "summary": "OpenAI not configured"}

        try:
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
            company_desc = knowledge_base.get("company_description", {})
            brand_guidelines = knowledge_base.get("brand_guidelines", {})

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": (
                        "Analyze Reddit thread sentiment. ONLY use the provided content. "
                        "Do NOT invent facts or statistics. "
                        f"Company context: {str(company_desc.get('overview',''))[:200]}. "
                        f"Brand tone: {brand_guidelines.get('tone','Professional')}. "
                        "Return JSON: {\"sentiment\": \"positive|neutral|negative\", \"sentiment_score\": 0-1, \"summary\": \"one sentence\"}"
                    )},
                    {"role": "user", "content": f"Title: {thread_title}\nContent: {thread_content[:800]}"}
                ],
                temperature=0,
                max_tokens=150,
                response_format={"type": "json_object"}
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f"‚ùå Thread analysis error: {e}")
            return {"sentiment": "neutral", "sentiment_score": 0.5, "summary": "Analysis unavailable"}


# Singleton
reddit_service = RedditIntelligenceService()
